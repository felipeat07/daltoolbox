{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering - dbscan\n",
    "## Libraries and Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“replacing previous import ‘dplyr::rename’ by ‘reshape::rename’ when loading ‘daltoolbox’”\n",
      "Warning message:\n",
      "“replacing previous import ‘class::condense’ by ‘reshape::condense’ when loading ‘daltoolbox’”\n",
      "Warning message:\n",
      "“replacing previous import ‘dplyr::filter’ by ‘stats::filter’ when loading ‘daltoolbox’”\n"
     ]
    }
   ],
   "source": [
    "# DAL ToolBox\n",
    "# version 1.0.50\n",
    "\n",
    "source(\"https://raw.githubusercontent.com/cefet-rj-dal/dal/main/examples/jupyter_daltoolbox.R\")\n",
    "\n",
    "#loading DAL\n",
    "load_daltoolbox() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris <- datasets::iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General entropy of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 1.584963\n"
     ]
    }
   ],
   "source": [
    "eval <- evaluate(clustering(), rep(1, nrow(iris)), iris$Species)\n",
    "print(eval$entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General function to test clustering methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clustering <- function(model, data, attribute) {\n",
    "  describe(model)\n",
    "  clu <- cluster(model, data)\n",
    "  print(table(clu))\n",
    "  eval <- evaluate(model, clu, attribute)\n",
    "  print(eval$entropy)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in cluster_dbscan(eps = 0.4, minPts = 3): unused argument (minPts = 3)\n",
     "output_type": "error",
     "traceback": [
      "Error in cluster_dbscan(eps = 0.4, minPts = 3): unused argument (minPts = 3)\nTraceback:\n",
      "1. test_clustering(cluster_dbscan(eps = 0.4, minPts = 3), iris[, \n .     1:4], iris[, 5])",
      "2. describe(model)   # at line 2 of file <text>"
     ]
    }
   ],
   "source": [
    "# dbscan\n",
    "test_clustering(cluster_dbscan(eps = 0.4, minPts = 3), iris[,1:4], iris[,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of normalization in clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in dbscan::dbscan(data, eps = obj$eps, MinPts = obj$MinPts):\n",
      "“converting argument MinPts (fpc) to minPts (dbscan)!”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clu\n",
      "  1   2 \n",
      " 50 100 \n",
      "[1] 0.6666667\n"
     ]
    }
   ],
   "source": [
    "norm_minmax <- fit(minmax(), iris)\n",
    "iris_minmax <- transform(norm_minmax, iris)\n",
    "test_clustering(cluster_dbscan(eps = 0.4, minPts = 3), iris_minmax[,1:4], iris_minmax[,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
